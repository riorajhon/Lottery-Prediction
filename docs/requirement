Spanish lotteries (Euromillones, La Primitiva, El Gordo).
1.historical data scraping
2.AI-driven prediction models
3.backtesting capabilities
4.supervised bet placement

-------------------------Data Collection & Storage:--------------------------------------
- Ethical scraping of historical data from official Spanish lottery websites (e.g., www.loteriasyapuestas.es).
    • Euromillones • La Primitiva • El Gordo
- Database: PostgreSQL or MongoDB.
- Automatic updates daily at 00:02 after each draw.
- Web scraping tools like BeautifulSoup or Scrapy, mimicking human behavior.

--------------------------AI Prediction Models:-----------------------------------------------------------
- Multiple AI models working collaboratively: Random Forest, Neural Networks (RNN/LSTM), Genetic/Evolutionary Algorithms, Bayesian Networks, and optionally Neuro-Symbolic AI.
- Hot and cold number analysis.
- Wheeling system for partial prize optimization.
- Monte Carlo simulations for expected value estimation on high jackpots.

• Random Forest
• Neural Networks (RNN / LSTM)
• Genetic / Evolutionary Algorithms
• Bayesian Networks
• (Optional) Neuro-Symbolic AI
-Neural networks (LSTM, RNN) to detect sequential patterns.
-Genetic algorithms to evolve better number combinations.
-Bayesian networks to model probabilities.
-Neuro-symbolic AI to combine pattern recognition with logical rules.
-Monte Carlo simulations to test thousands of scenarios.
-Ensemble models like Random Forest to combine multiple techniques.

After the first draw (only one historical result), the system should run thousands or even millions of simulations and suggest how many bets I should place — whether it's 10, 20, 50, 100, 300, or even 3,000 bets (but I decide the number of bets, the system only suggests) — and show the probability of winning based on that volume.

When the next draw happens, the system should compare the prediction with the actual result and tell me:
"If you had placed X bets using this model, you would have won this prize."

Over time, as more draws are added to the history, the system should learn and improve, gradually reducing the number of bets needed to achieve consistent results.

---------------------------Backtesting:----------------------------------------------------
- Test models against historical data with performance evaluation.
- Large-scale simulation (may require distributed computing).

--------------------------Betting Automation (Selenium):------------------------------------
- Automated login to official website without storing credentials (encrypted sessions or fresh login).
- Balance check before placing bets.
- Captcha handling via manual intervention or external service.
- Supervised bet placement with mandatory confirmation screen before finalizing.
- Save receipts/proof of bets.

--------------------------Interface & Access:--------------------------------------
- Web app using Django/FastAPI + React hosted on the cloud for remote access.
- Dashboard featuring: FullCalendar/agenda view, draw results, generated predictions, betting history, and backtesting reports.
• FullCalendar / agenda view
• Draw results
• Generated predictions
• Betting history
• Backtesting reports
-------------------------------------------------------------------------------------------
Complementing the previous explanation:
When the system starts learning, it should work as follows:
After the first draw (only one historical result available), the system will analyze that result and run millions of simulations to generate possible number combinations and betting strategies.
When the second draw result is released, the system will:
Compare the simulations made after the first draw with the actual result of the second draw.
Tell me: "If you had placed X bets using this model, you would have won the first prize (jackpot)."
Additionally, based on those X bets, the system will also tell me how many smaller prizes I would have won (category 3, 4, 5, reintegro, etc.) and the total amount I would have recovered from those smaller prizes.
This same process will repeat for every new draw, and independently for each of the three lotteries (Euromillones, La Primitiva, El Gordo).
Over time, the system will build a complete historical record showing:
How many bets would have been needed to win the jackpot in each draw
How many smaller prizes would have been won with that number of bets
What the total return would have been from those smaller prizes
And how these numbers evolve as more data becomes available
This way, I can clearly see the relationship between the number of bets placed, the probability of hitting the jackpot, and the consistent return from smaller prizes — helping me make better decisions over time.

python -m uvicorn main:app --reload --host 0.0.0.0 --port 8000
